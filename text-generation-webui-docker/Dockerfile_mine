#FROM nvidia/cuda:12.1.0-devel-ubuntu22.04 AS env_base
FROM nvidia/cuda:11.2.2-devel-ubuntu20.04 AS env_base

#FROM nvidia/cuda:12.1.0-devel-ubuntu22.04 AS env_base
#FROM python:3.9.18-slim as base
#FROM python:3.9.18-slim as env_base
#FROM nvidia/cuda:11.1.1-devel-ubi8 as env_base
#FROM pytorch/pytorch:1.0-cuda10.0-cudnn7-runtime AS env_base
#FROM pytorch/pytorch:1.2-cuda10.0-cudnn7-devel AS env_base
# Pre-reqs
#Ubuntu
ENV DEBIAN_FRONTEND noninteractive
RUN apt-get update && apt-get install --no-install-recommends -y \
    git vim build-essential python3-dev python3-venv python3-pip

RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone
RUN apt install software-properties-common -y
RUN add-apt-repository ppa:deadsnakes/ppa
RUN apt-get update -y
RUN apt install python3.11 python3-pip -y
#RUN apt-get update && \
#    apt-get install -y python3.11

RUN pip install --upgrade pip
# Instantiate venv and pre-activate
RUN pip3 install virtualenv
RUN virtualenv /venv
# Credit, Itamar Turner-Trauring: https://pythonspeed.com/articles/activate-virtualenv-dockerfile/
ENV VIRTUAL_ENV=/venv
RUN python3 -m venv $VIRTUAL_ENV
ENV PATH="$VIRTUAL_ENV/bin:$PATH"
#RUN pip3 install --upgrade pip setuptools && \
#    pip3 install torch torchvision torchaudio

#FROM env_base AS app_base
# Copy and enable all scripts
COPY ./scripts /scripts
RUN chmod +x /scripts/*
### DEVELOPERS/ADVANCED USERS ###
# Clone oobabooga/text-generation-webui
#RUN git clone https://github.com/oobabooga/text-generation-webui /src
# Use script to check out specific version
#ARG VERSION_TAG
#ENV VERSION_TAG=${VERSION_TAG}
#RUN . /scripts/checkout_src_version.sh
# To use local source: comment out the git clone command then set the build arg `LCL_SRC_DIR`
ARG LCL_SRC_DIR="text-generation-webui/"
COPY ${LCL_SRC_DIR} /src
#################################
ENV LLAMA_CUBLAS=1
# Copy source to app
RUN cp -ar /src /app
# Install oobabooga/text-generation-webui
RUN --mount=type=cache,target=/root/.cache/pip pip3 install -r /app/requirements.txt
# Install extensions
RUN --mount=type=cache,target=/root/.cache/pip \
    chmod +x /scripts/build_extensions.sh && . /scripts/build_extensions.sh
RUN conda install -c conda-forge cudatoolkit-dev
ENV CUDA_HOME=$CONDA_PREFIX
# Clone default GPTQ
#RUN git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda /app/repositories/GPTQ-for-LLaMa
# Build and install default GPTQ ('quant_cuda')
#ARG TORCH_CUDA_ARCH_LIST="6.1;7.0;7.5;8.0;8.6+PTX"
#RUN cd /app/repositories/GPTQ-for-LLaMa/ && python3 setup_cuda.py install
# Install flash attention for exllamav2
#RUN pip install flash-attn --no-build-isolation

#FROM pytorch/pytorch:1.0-cuda10.0-cudnn7-runtime AS base
# Runtime pre-reqs
#RUN apt-get update && apt-get install --no-install-recommends -y \
#    python3-venv python3-dev git
# Copy app and src
#COPY --from=app_base /app /app
#COPY --from=app_base /src /src
# Copy and activate venv
#COPY --from=app_base /venv /venv
#ENV VIRTUAL_ENV=/venv
#ENV VIRTUAL_ENV=/venv


#RUN python3 -m venv $VIRTUAL_ENV
#ENV PATH="$VIRTUAL_ENV/bin:$PATH"
# Finalise app setup
WORKDIR /app
EXPOSE 7860
EXPOSE 7861
EXPOSE 7862
EXPOSE 7863
EXPOSE 5000
EXPOSE 5005
# Required for Python print statements to appear in logs
ENV PYTHONUNBUFFERED=1
# Force variant layers to sync cache by setting --build-arg BUILD_DATE
ARG BUILD_DATE
ENV BUILD_DATE=$BUILD_DATE
RUN echo "$BUILD_DATE" > /build_date.txt
ARG VERSION_TAG
ENV VERSION_TAG=$VERSION_TAG
RUN echo "$VERSION_TAG" > /version_tag.txt
# Copy and enable all scripts
COPY ./scripts /scripts
COPY ./config/models /app/models
RUN chmod +x /scripts/*
# Run
ENTRYPOINT ["/scripts/docker-entrypoint.sh"]

FROM env_base AS default
RUN echo "DEFAULT" >> /variant.txt
ENV EXTRA_LAUNCH_ARGS="CUDA_LAUNCH_BLOCKING=1"
#COPY ./config/models /app
CMD ["python3", "/app/server.py"]
